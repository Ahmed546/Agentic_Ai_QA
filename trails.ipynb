{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_huggingface import HuggingFaceEndpoint\n",
    "# import re\n",
    "# import httpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# import torch\n",
    "# from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import re\n",
    "import httpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "class ChatBot:\n",
    "    def __init__(self, system=\"\"):\n",
    "        self.system = system\n",
    "        self.messages = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "    \n",
    "    def __call__(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "    \n",
    "    def execute(self):\n",
    "        completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=self.messages)\n",
    "        return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer.\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point\n",
    "syntax if necessary\n",
    "\n",
    "wikipedia:\n",
    "e.g. wikipedia: Django\n",
    "Returns a summary from searching Wikipedia\n",
    "\n",
    "simon_blog_search:\n",
    "e.g. simon_blog_search: Django\n",
    "Search Simon's blog for that term\n",
    "\n",
    "Example session:\n",
    "Question: What is the capital of France?\n",
    "Thought: I should look up France on Wikipedia\n",
    "Action: wikipedia: France\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this:\n",
    "Observation: France is a country. The capital is Paris.\n",
    "\n",
    "You then output:\n",
    "Answer: The capital of France is Paris\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_re = re.compile(r'^Action: (\\w+): (.*)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wikipedia(q):\n",
    "    response = httpx.get(\"https://en.wikipedia.org/w/api.php\", params={\n",
    "        \"action\": \"query\",\n",
    "        \"list\": \"search\",\n",
    "        \"srsearch\": q,\n",
    "        \"format\": \"json\"\n",
    "    })\n",
    "    return response.json()[\"query\"][\"search\"][0][\"snippet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simon_blog_search(q):\n",
    "    response = httpx.get(\"https://datasette.simonwillison.net/simonwillisonblog.json\", params={\n",
    "        \"sql\": \"\"\"\n",
    "        select\n",
    "          blog_entry.title || ': ' || substr(html_strip_tags(blog_entry.body), 0, 1000) as text,\n",
    "          blog_entry.created\n",
    "        from\n",
    "          blog_entry join blog_entry_fts on blog_entry.rowid = blog_entry_fts.rowid\n",
    "        where\n",
    "          blog_entry_fts match escape_fts(:q)\n",
    "        order by\n",
    "          blog_entry_fts.rank\n",
    "        limit\n",
    "          1\n",
    "        \"\"\".strip(),\n",
    "        \"_shape\": \"array\",\n",
    "        \"q\": q,\n",
    "    })\n",
    "    return response.json()[0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(what):\n",
    "    return eval(what)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_actions = {\n",
    "    \"wikipedia\": wikipedia,\n",
    "    \"calculate\": calculate,\n",
    "    \"simon_blog_search\": simon_blog_search\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(question, max_turns=5):\n",
    "    i = 0\n",
    "    bot = ChatBot(prompt)\n",
    "    next_prompt = question\n",
    "    while i < max_turns:\n",
    "        i += 1\n",
    "        result = bot(next_prompt)\n",
    "        print(result)\n",
    "        actions = [action_re.match(a) for a in result.split('\\n') if action_re.match(a)]\n",
    "        if actions:\n",
    "            action, action_input = actions[0].groups()\n",
    "            if action not in known_actions:\n",
    "                raise Exception(f\"Unknown action: {action}: {action_input}\")\n",
    "            print(\" -- running {} {}\".format(action, action_input))\n",
    "            observation = known_actions[action](action_input)\n",
    "            print(\"Observation:\", observation)\n",
    "            next_prompt = f\"Observation: {observation}\"\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query(\"What does Pakistan share borders with?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.llms import HuggingFaceEndpoint\n",
    "# from huggingface_hub import whoami\n",
    "\n",
    "# class ChatBot:\n",
    "#     def __init__(self, \n",
    "#                  repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\", \n",
    "#                  system=\"\", \n",
    "#                  token=\"\", \n",
    "#                  temperature=0.7, \n",
    "#                  max_length=128):\n",
    "#         if not token:\n",
    "#             raise ValueError(\"A Hugging Face authentication token is required.\")\n",
    "\n",
    "#         # Validate Token\n",
    "#         try:\n",
    "#             whoami(token=token)\n",
    "#         except Exception as e:\n",
    "#             raise ValueError(f\"Invalid Hugging Face token: {e}\")\n",
    "\n",
    "#         self.llm = HuggingFaceEndpoint(\n",
    "#             repo_id=repo_id,\n",
    "#             token=token,\n",
    "#             temperature=temperature,\n",
    "#             model_kwargs={\"max_length\": max_length}\n",
    "#         )\n",
    "\n",
    "#         self.messages = []\n",
    "#         if system:\n",
    "#             self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "#     def __call__(self, message):\n",
    "#         self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "#         try:\n",
    "#             result = self.execute()\n",
    "#             self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "#             return result\n",
    "#         except Exception as e:\n",
    "#             return f\"Error during generation: {e}\"\n",
    "\n",
    "#     def execute(self):\n",
    "#         conversation = \"\".join(\n",
    "#             f\"{msg['role'].capitalize()}: {msg['content']}\\n\" for msg in self.messages\n",
    "#         )\n",
    "#         conversation += \"Assistant:\"\n",
    "#         try:\n",
    "#             response = self.llm(conversation)\n",
    "#             return response.strip()\n",
    "#         except Exception as e:\n",
    "#             raise RuntimeError(f\"Error during generation: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
